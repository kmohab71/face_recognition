{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMDYWW7BU82e"
   },
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import regex \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rwtwi-lJrEDB"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def read_dataset(path):\n",
    "  data= np.zeros([400,10305])\n",
    "  i=0\n",
    "  images_list = []\n",
    "  for filename in glob.glob(path+\"/*/*.pgm\"): \n",
    "    im=Image.open(filename)\n",
    "    images_list.append(im)\n",
    "    l=regex.split(r'/', filename)\n",
    "    l2= regex.split(r's', l[1])\n",
    "    arr = np.array(im)\n",
    "    data[i,0:10304]=arr.reshape(1,10304)\n",
    "    data[i, -1]=l2[1]\n",
    "    i+=1\n",
    "  return data, images_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hts1FOPRRCO9"
   },
   "outputs": [],
   "source": [
    "def data_splitting():\n",
    "    test_X = np.zeros([200,10304])\n",
    "    train_X = np.zeros([200,10304])\n",
    "    test_y= np.zeros(200)\n",
    "    train_y=np.zeros(200)\n",
    "    for i in range(data.shape[0]):\n",
    "        if i%2 == 0:\n",
    "            test_X[int(i/2)]=data[i,:-1]\n",
    "            test_y[int(i/2)]= data[i,-1]\n",
    "        else:\n",
    "            train_X[int((i-1)/2)]=data[i,:-1]\n",
    "            train_y[int((i-1)/2)]= data[i,-1] \n",
    "    return train_X, train_y, test_X, test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trained_data_splitting(x):\n",
    "    rows,cols=x.shape\n",
    "    test_X = np.zeros([200,cols])\n",
    "    train_X = np.zeros([200,cols])\n",
    "    for i in range(x.shape[0]):\n",
    "        if i%2 == 0:\n",
    "            test_X[int(i/2)]=x[i,:]\n",
    "        else:\n",
    "            train_X[int((i-1)/2)]=x[i,:]\n",
    "    return train_X, test_X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hs9r-A4YTmpc"
   },
   "outputs": [],
   "source": [
    "def visualize(images,i):\n",
    "  plt.imshow(images[i])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_FXsVBSuDRg"
   },
   "outputs": [],
   "source": [
    "data, images= read_dataset(\"orl_faces\") \n",
    "train_x, train_y, test_x, test_y= data_splitting()\n",
    "#print(train_y)\n",
    "#visualize(images, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FOTV(eig_vals,totVar,alphas):\n",
    "    I=dict()\n",
    "    for alpha in alphas:\n",
    "        expVar=0.0\n",
    "        i=0\n",
    "        while expVar <= (alpha * totVar): \n",
    "            expVar+=eig_vals[i]\n",
    "            i+=1\n",
    "        I[alpha]=i\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pCA(dataMatrix):\n",
    "    transformed=dict()\n",
    "    X=dataMatrix[:,:]\n",
    "    num_data, dim = X.shape\n",
    "    mean_X = X.mean(axis=0)\n",
    "    X = X - mean_X \n",
    "    cov_mat = np.dot(X.T, X)/(num_data) # covariance matrix\n",
    "    eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "    totVar = sum(eig_vals)\n",
    "    idx = eig_vals.argsort()[::-1]   \n",
    "    eig_vals = eig_vals[idx]\n",
    "    eig_vecs = eig_vecs[:,idx]\n",
    "    num = FOTV(eig_vals,totVar,[0.8,0.85,0.9,0.95])\n",
    "    for key, vals in num.items(): \n",
    "        reducedVec=eig_vecs[:vals,:]\n",
    "        transformed[key]=np.absolute(X.dot(reducedVec.T))\n",
    "        print(len(transformed))\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x=pCA(data[:][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmodel_score(train_X, test_X,neighbors):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "    knn_model.fit(train_X, train_y) \n",
    "    y_predict = knn_model.score(test_X,test_y)\n",
    "    return(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 44)\n",
      "0.8 0.765\n",
      "(399, 68)\n",
      "0.85 0.83\n",
      "(399, 110)\n",
      "0.9 0.88\n",
      "(399, 190)\n",
      "0.95 0.895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, vals in x.items(): \n",
    "    print(vals.shape)\n",
    "    train_X, test_X=trained_data_splitting(vals)\n",
    "    score=kmodel_score(train_X, test_X,1)\n",
    "    print(key,score)\n",
    "len(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KXEEiA6NV1yp"
   },
   "outputs": [],
   "source": [
    "def pca():\n",
    "  pca = PCA(n_components= 200)\n",
    "  pca_model= pca.fit(train_x)\n",
    "  new_dimensions = pca_model.transform(train_x)  \n",
    "  #plt.scatter(new_dimensions[:,0],new_dimensions[:,1])  \n",
    "  #print(pca.explained_variance_ratio_)  \n",
    "  #print(new_dimensions.shape)\n",
    "  #print(pca.explained_variance_ratio_)\n",
    "  return  new_dimensions\n",
    "\n",
    "new_dimensions= pca()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# K-NN classifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh.fit(train_x,train_y) \n",
    "neigh.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA(train_x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "face_recognition.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
