{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import regex \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "  data= np.zeros([400,10305])\n",
    "  i=0\n",
    "  iamges_list = []\n",
    "  for filename in glob.glob(path+\"/*/*.pgm\"): \n",
    "\n",
    "    im=Image.open(filename)\n",
    "    iamges_list.append(im)\n",
    "    l=regex.split(r'/', filename)\n",
    "    l2= regex.split(r's', l[1])\n",
    "    arr = np.array(im)\n",
    "    data[i,0:10304]=arr.reshape(1,10304)\n",
    "    data[i, -1]=l2[1]\n",
    "    i+=1\n",
    "  return data, iamges_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitting():\n",
    "    test_X = np.zeros([200,10305])\n",
    "    train_X = np.zeros([200,10305])\n",
    "    test_y= np.zeros(200)\n",
    "    train_y=np.zeros(200)\n",
    "    for i in range(data.shape[0]):\n",
    "        if i%2 == 0:\n",
    "            test_X[int(i/2)]=data[i,0:10305]\n",
    "            test_y[int(i/2)]= data[i,10304]\n",
    "        else:\n",
    "            train_X[int((i-1)/2)]=data[i,0:10305]\n",
    "            train_y[int((i-1)/2)]= data[i,10304] \n",
    "    return train_X, train_y, test_X, test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(images,i):\n",
    "  plt.imshow(images[i])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(data):\n",
    "    classes= []\n",
    "    for i in range (41):\n",
    "        indecies= np.argwhere(data[:,-1]== i)\n",
    "        classes.append(data[indecies,:].reshape(len(indecies),data.shape[1]))      \n",
    "    classes.pop(0)\n",
    "    return classes\n",
    "\n",
    "def centralized(classes,classes_Mean):\n",
    "    z=[]\n",
    "    for i, x in enumerate(classes):\n",
    "        z.append(x - (np.ones(x.shape)*classes_Mean[i]))\n",
    "    z=np.array(z)\n",
    "    #Z=Z.reshape(400,10305)\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(data):\n",
    "    classes= get_classes(data)\n",
    "    Means= np.mean(data,0)\n",
    "    \n",
    "    list = [np.mean(x, axis=0) for x in classes]\n",
    "    classes_Mean= np.array(list)   \n",
    "    print(classes_Mean.shape)\n",
    "    \n",
    "    SB=0\n",
    "    for i, x in enumerate(classes):\n",
    "        SB+=np.dot(x.shape[0]*(classes_Mean[i] - Means),(classes_Mean[1] - Means).T)\n",
    "\n",
    "    ##..........center class matrices..........##\n",
    "    Z= certerlaized(classes,classes_Mean) \n",
    "    \n",
    "    ##..........Within class scatter matrix...........##\n",
    "    s= []\n",
    "    S_sum= np.zeros([Z.shape[1], Z.shape[1]])\n",
    "    for i in range (len(classes)):\n",
    "        s.append(Z[i].dot(Z[i].T))\n",
    "        S_sum+=Z[i].dot(Z[i].T)\n",
    "    print(\"number of classes=\", len(s), \"Summ_of S=\", S_sum.shape)\n",
    "    \n",
    "    \n",
    "    eigval, eigvec = np.linalg.eig(np.dot(np.linalg.inv(S_sum), SB))\n",
    "    print(eigvec.shape)\n",
    "    \n",
    "LDA(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classifer(X_train_transformed, y_train,preprocessor_type):\n",
    "\n",
    "    #................................training........................................#    \n",
    "    parameters = {'n_neighbors':[1,3,5,7]}\n",
    "    KNN=KNeighborsClassifier()\n",
    "    cv= KFold(n_splits=5,shuffle=True, random_state=5)\n",
    "    KNN_opt = GridSearchCV(KNN, parameters,cv=cv,n_jobs=-1,return_train_score=True)\n",
    "    KNN_opt.fit(X_train_transformed,  y_train)\n",
    "    print(\"Best parameters:\",KNN_opt.best_params_)\n",
    "    print(\"Best score=\",KNN_opt.best_score_ )\n",
    "    mean_train_score=KNN_opt.cv_results_['mean_train_score']\n",
    "    mean_test_score=KNN_opt.cv_results_['mean_test_score']\n",
    "    param= KNN_opt.cv_results_['params']\n",
    "    \n",
    "    \n",
    "    #..........................visualizing learning curves and tuning acuracies.......................#   \n",
    "    title = \"Learning Curves for best estimator using  \"+ preprocessor_type\n",
    "    plt=plot_learning_curve(KNN_opt, title, X_train_transformed,  y_train, cv=cv)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(parameters['n_neighbors'], mean_test_score, 'ro')\n",
    "    plt.show\n",
    "    return mean_train_score, mean_test_score, parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, images= read_dataset(\"orl_faces\") \n",
    "train_x, train_y, test_x, test_y= data_splitting()\n",
    "\n",
    "\n",
    "## call PCA here and get PCA transformed X_train\n",
    "\n",
    "## first for PCA\n",
    "#preprocessor_type= \"PCA\"\n",
    "#mean_train_score, mean_test_score,parameters =KNN_classifer(train_x, train_y, preprocessor_type)\n",
    "\n",
    "\n",
    "## call PCA here and get PCA transformed X_train\n",
    "\n",
    "## second for LDA \n",
    "preprocessor_type=\"LDA\"\n",
    "mean_train_score, mean_test_score,parameters =KNN_classifer(train_x, train_y,preprocessor_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
